---
title: "NHANES 2003–2006: Sodium, Potassium, and Blood Pressure"
subtitle: "A Survey-Weighted Regression Example with phonto"
author: "Johnny Zhao"
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    code-fold: show
execute:
  echo: true
  warning: false
  message: false
vignette: >
  %\VignetteIndexEntry{NHANES Sodium, Potassium, and Blood Pressure (Survey Analysis)}
  %\VignetteEngine{quarto}
  %\VignetteEncoding{UTF-8}
---

# Introduction

In this tutorial, we demonstrate how to reproduce and extend a textbook analysis of the relationship between dietary sodium, dietary potassium, and blood pressure, using NHANES data from 2003–2006.\
The goal is to show how to:

-   Retrieve and merge NHANES datasets programmatically with the `phonto` and `nhanesA` packages.

-   Apply the appropriate survey weights to account for the complex sampling design.

-   Fit survey-weighted regression models to estimate associations between nutrient intake and systolic/diastolic blood pressure.

-   Compare results with those presented in the textbook to validate reproducibility.

# **Packages**

We begin by loading the packages required for data extraction, processing, and analysis.

-   phonto and nhanesA: provide programmatic access to NHANES variables and allow flexible queries across cycles.

-   survey: provides tools for creating complex survey designs and fitting weighted regression models.

```{r}
library(phonto)    # Epiconnector tools for reproducible NHANES access
library(nhanesA)   # Interface to NHANES public datasets
library(survey)    # Complex survey analysis
library(dplyr)     # Data wrangling
library(tidyr)     # Data wrangling
```

# **Data Sources (revised)**

We use four NHANES domains across two cycles (2003–2004 “C” and 2005–2006 “D”): **DEMO**, **BPX**, **BMX**, **DR1TOT**.\
To remain faithful to the textbook replication, we *retain exactly* the fields it kept and handle cycle differences explicitly.

**DEMO (12 variables, both cycles C & D)**\
These are kept verbatim for design/weights/QC and to mirror the textbook columns:

-   `SEQN`, `SDDSRVYR`, `RIDSTATR`, `RIDEXMON`,\
    `RIAGENDR`, `RIDAGEYR`, `RIDAGEMN`, `RIDAGEEX`,\
    `WTINT2YR`, `WTMEC2YR`, `SDMVPSU`, `SDMVSTRA`.

**BPX (all columns, both cycles C & D)**\
We pull the full BPX tables. For the **D cycle**, if pre-averaged values are absent, we will compute:\
`BPXSAR = mean(BPXSY1:BPXSY4, na.rm=TRUE)` and `BPXDAR = mean(BPXDI1:BPXDI4, na.rm=TRUE)`.

**BMX (both cycles C & D)**

-   `SEQN`, `BMXBMI`.

**DR1TOT (dietary recall Day 1; cycle-specific column keeps)**\
To mirror the textbook column selections:

-   C cycle: keep columns 1:52, 63, 64.

-   D cycle: keep columns 1:52, 64, 65.\
    (In practice, our modeling uses `DR1TSODI` and `DR1TPOTA`; we keep the broader sets for fidelity/QC. Because `phonto`/`nhanesA` access by *names*, the wrangling step will fetch full tables and then select by position to reproduce the textbook’s choice.)

**Code: declare the targets we will keep (for the upcoming extraction/wrangling)**

```{r}
# DEMO: exact 12 variables (C and D)
DEMO_keep <- c(
  "SEQN","SDDSRVYR","RIDSTATR","RIDEXMON",
  "RIAGENDR","RIDAGEYR","RIDAGEMN","RIDAGEEX",
  "WTINT2YR","WTMEC2YR","SDMVPSU","SDMVSTRA"
)

# BPX: keep ALL columns (we'll pull the whole table per cycle)
BPX_keep_all <- TRUE  # used as a flag in the extraction step

# BMX: SEQN + BMI (C and D)
BMX_keep <- c("SEQN","BMXBMI")

# DR1TOT: cycle-specific positional keeps (to mirror textbook)
DR1TOT_C_keep_idx <- c(1:52, 63, 64)
DR1TOT_D_keep_idx <- c(1:52, 64, 65)

# For modeling we will also ensure these two named vars exist after selection:
DIET_named_vars <- c("DR1TSODI","DR1TPOTA")
```

> In the Data Extraction section, we will: (i) use `nhanesA`/`phonto` to fetch the full tables for each domain and cycle; (ii) select `DEMO_keep`, `BMX_keep`, all of BPX, and the cycle-specific slices of DR1TOT by position; (iii) compute `BPXSAR/BPXDAR` for 2005–2006 as needed; and (iv) merge by `SEQN` to create `nhanes34`, `nhanes56`, and then stack to a single analytic file.

# Data Extraction

We programmatically retrieve the four domains: **DEMO**, **BPX**, **BMX**, **DR1TOT**; from cycles **C (2003–2004)** and **D (2005–2006)**.\
To mirror the workflow while keeping reproducibility, we:

1.  pull each table by cycle-tagged name (e.g., `DEMO_C`, `BPX_D`) using our package API;

2.  keep the exact subsets the textbook used (DEMO = 12 variables, BMX minimal, BPX full table, DR1TOT by column positions);

3.  merge within each cycle by `SEQN` to produce `nhanes34` and `nhanes56`.

> Notes
>
> -   We keep DR1TOT by position (C: `1:52, 63, 64`; D: `1:52, 64, 65`) to stay faithful to the textbook selection.
>
> -   We do no transformations here; construction of `BPXSAR/BPXDAR` for 2005–2006 and unit conversions will be done in the next section to keep responsibilities clean.

### Cycle C (2003–2004)

We load each table for cycle C and immediately select the textbook columns.

```{r}
# Pull raw tables by cycle-tagged names
demo_c  <- nhanes("DEMO_C")
bpx_c   <- nhanes("BPX_C")
bmx_c   <- nhanes("BMX_C")
diet_c0 <- nhanes("DR1TOT_C")

# Select columns per textbook
demo_c <- dplyr::select(demo_c, dplyr::all_of(DEMO_keep))
bmx_c  <- dplyr::select(bmx_c,  dplyr::all_of(BMX_keep))
diet_c <- diet_c0[, DR1TOT_C_keep_idx, drop = FALSE]

# Merge within-cycle by SEQN (inner joins, mirroring textbook `merge(..., by="SEQN")`)
nhanes34 <- demo_c |>
  dplyr::inner_join(bpx_c, by = "SEQN") |>
  dplyr::inner_join(bmx_c, by = "SEQN") |>
  dplyr::inner_join(diet_c, by = "SEQN")

# Quick QC
dim(nhanes34)
head(nhanes34)[, 1:10]
```

### Cycle D (2005–2006)

Likewise for cycle D. We keep the entire BPX table now and will compute means for `BPXSAR/BPXDAR` (if missing) in the next section.

```{r}
demo_d  <- nhanes("DEMO_D")
bpx_d   <- nhanes("BPX_D")
bmx_d   <- nhanes("BMX_D")
diet_d0 <- nhanes("DR1TOT_D")

demo_d <- dplyr::select(demo_d, dplyr::all_of(DEMO_keep))
bmx_d  <- dplyr::select(bmx_d,  dplyr::all_of(BMX_keep))
diet_d <- diet_d0[, DR1TOT_D_keep_idx, drop = FALSE]

nhanes56 <- demo_d |>
  dplyr::inner_join(bpx_d, by = "SEQN") |>
  dplyr::inner_join(bmx_d, by = "SEQN") |>
  dplyr::inner_join(diet_d, by = "SEQN")
```

# Data Cleaning and Preprocessing

We now harmonize variables across cycles and prepare analysis fields:

-   **SBP/DBP means:** In cycle D (2005–2006), pre-averaged `BPXSAR`/`BPXDAR` may be absent, so we compute means from the four replicate readings (`BPXSY1` to `BPXSY4`, `BPXDI1` to `BPXDI4`) and use them when needed.

-   **Units:** Convert sodium (`DR1TSODI`) and potassium (`DR1TPOTA`) from mg to g/day for interpretability and consistency with the textbook.

-   **Weights:** Create a 4-year dietary weight as `fouryearwt = WTDRD1/2` when combining two 2-year cycles (2003–2004 and 2005–2006).

-   **No filtering here:** We keep the full dataset; we will subset to non-missing `WTDRD1` inside the survey design call to mirror the textbook workflow.

```{r}
# If you stacked earlier previews as `nhanes_raw`, use it; otherwise bind now:
nhanes <- dplyr::bind_rows(nhanes34, nhanes56)

nhanes <- nhanes %>%
  # 1) Compute SBP/DBP replicate means and backfill missing pre-averaged values
  mutate(
    sbp_mean = rowMeans(
      cbind(BPXSY1, BPXSY2, BPXSY3, BPXSY4),
      na.rm = TRUE
    ),
    dbp_mean = rowMeans(
      cbind(BPXDI1, BPXDI2, BPXDI3, BPXDI4),
      na.rm = TRUE
    ),
    BPXSAR = ifelse(is.na(BPXSAR), sbp_mean, BPXSAR),
    BPXDAR = ifelse(is.na(BPXDAR), dbp_mean, BPXDAR)
  ) %>%
  # 2) Convert sodium/potassium from mg to g per day
  mutate(
    sodium    = DR1TSODI / 1000,
    potassium = DR1TPOTA / 1000
  ) %>%
  # 3) Construct 4-year dietary weight (two cycles combined)
  mutate(
    fouryearwt = WTDRD1 / 2
  )

# Quick QC (optional, keep in tutorial for transparency)
summary(select(nhanes, BPXSAR, BPXDAR, sodium, potassium, fouryearwt))
sum(is.na(nhanes$WTDRD1))  # survey design will subset these out
```

**Notes**

-   We compute `sbp_mean`/`dbp_mean` for all rows to keep the code simple, but only use them to fill in `BPXSAR`/`BPXDAR`when those pre-averaged fields are missing (primarily cycle D).

-   We do not alter `RIAGENDR`, `RIDAGEYR`, or `BMXBMI` types here to remain faithful to the textbook; if needed for extensions, factor recoding can be added later.

-   In the next section (Survey design), we will create the complex survey object with `id = ~SDMVPSU`, `strata = ~SDMVSTRA`, and `weights = ~fouryearwt`, and use `data = subset(nhanes, !is.na(WTDRD1))` to mirror the textbook subsetting rule.

# Survey Design

We now create the complex survey design object. NHANES uses a multistage, stratified design with masked variance units. The key elements are:

-   **Strata/PSU:** `SDMVSTRA` (strata) and `SDMVPSU` (primary sampling units).

-   **Weights:** Because our analysis is based on 24-hour dietary recall, Day 1, the appropriate weight is `WTDRD1`. After combining two 2-year cycles (2003–2004 and 2005–2006), we follow the textbook and construct a 4-year dietary weight as `fouryearwt = WTDRD1 / 2`.

-   **Analytic subset:** As in the textbook, we restrict to participants with non-missing `WTDRD1` (the dietary recall analytic sample).

In keeping with the textbook, we do not add new columns for unit conversions in the raw `nhanes` data frame. Instead, we create sodium and potassium (in g/day) as part of the survey design via `survey::update()`.

```{r}
des <- svydesign(
  id      = ~SDMVPSU,
  strata  = ~SDMVSTRA,
  weights = ~fouryearwt,
  nest    = TRUE,
  data    = subset(nhanes, !is.na(WTDRD1))
)

# Define sodium & potassium in g/day within the design object
des <- update(des,
  sodium = DR1TSODI / 1000,  # mg -> g/day
  potassium = DR1TPOTA / 1000   # mg -> g/day
)
```

**Notes**

-   `nest = TRUE` ensures PSUs are treated as nested within strata across combined cycles, which is standard for NHANES.

-   If your environment yields “lonely PSU” warnings, set `options(survey.lonely.psu = "adjust")` (or `"certainty"`) as shown above; this mirrors best practices illustrated in `survey_weights_tutorial.rmd`.

-   We keep `WTINT2YR` and `WTMEC2YR` in the dataset for completeness/QC, but the dietary models will use `fouryearwt`derived from `WTDRD1`.

-   Keeping Na/K as `update()` variables (rather than columns in `nhanes`) exactly matches the textbook structure and avoids bumping the column count.

Next, we’ll fit the survey-weighted models that replicate Table 5.1 (systolic/diastolic, stepwise adjustment) and perform a joint Wald test for sodium and potassium.

# Models

We now fit survey-weighted linear models for systolic (SBP, `BPXSAR`) and diastolic (DBP, `BPXDAR`) blood pressure.\
Following the textbook, we add covariates stepwise:

-   Model 0: sodium + potassium (unadjusted)

-   Model 1: + age (`RIDAGEYR`)

-   Model 2: + sex (`RIAGENDR`)

-   Model 3: + BMI (`BMXBMI`)

Sodium and potassium are already defined in g/day within the design object (`des`) via `update()` in the previous section.

```{r}
## Systolic blood pressure (SBP) models:
m0 <- svyglm(BPXSAR ~ sodium + potassium, design = des)
m1 <- svyglm(BPXSAR ~ sodium + potassium + RIDAGEYR, design = des)
m2 <- svyglm(BPXSAR ~ sodium + potassium + RIDAGEYR + RIAGENDR, design = des)
m3 <- svyglm(BPXSAR ~ sodium + potassium + RIDAGEYR + RIAGENDR + BMXBMI, design = des)

summary(m0); summary(m1); summary(m2); summary(m3)

# Joint (Wald) test for sodium & potassium in the fully adjusted SBP model
wald_sbp <- regTermTest(m3, ~ potassium + sodium, df = NULL)
wald_sbp
```

```{r}
## Diastolic blood pressure (DBP) models:
m4 <- svyglm(BPXDAR ~ sodium + potassium, design = des)
m5 <- svyglm(BPXDAR ~ sodium + potassium + RIDAGEYR, design = des)
m6 <- svyglm(BPXDAR ~ sodium + potassium + RIDAGEYR + RIAGENDR, design = des)
m7 <- svyglm(BPXDAR ~ sodium + potassium + RIDAGEYR + RIAGENDR + BMXBMI, design = des)

summary(m4); summary(m5); summary(m6); summary(m7)
```

### Compact coefficient tables (for later comparison)

To facilitate the comparison of results, the chunck below assembles tidy mini-tables for sodium and potassium across the stepwise models using only base R:

```{r}
coef_table <- function(mod_list, model_names, keep_terms = c("sodium","potassium")) {
  do.call(rbind, lapply(seq_along(mod_list), function(i) {
    s  <- summary(mod_list[[i]])
    co <- coef(s)
    co <- co[rownames(co) %in% keep_terms, , drop = FALSE]
    data.frame(
      model = model_names[i],
      term  = rownames(co),
      estimate = co[, "Estimate"],
      se       = co[, "Std. Error"],
      p_value  = co[, "Pr(>|t|)"],
      row.names = NULL
    )
  }))
}

tab_sbp <- coef_table(list(m0,m1,m2,m3), c("m0","m1","m2","m3"))
tab_dbp <- coef_table(list(m4,m5,m6,m7), c("m4","m5","m6","m7"))

# Preview:
# head(tab_sbp); head(tab_dbp)
```

**Notes**

-   `df = NULL` in `regTermTest()` uses the design-based degrees of freedom, which is appropriate for NHANES.

-   We’ll visualize diagnostics (residual vs. fitted, partial residual smoothers) in the next section.

-   Keep these objects (`m0`–`m7`, `wald_sbp`, and the `tab_*` tables) in the session; we’ll compare them with the textbook numbers in **Results comparison**.

**Reproduced Table 5.1** **from desktop environment:**

| Model | Systolic BP Sodium | Systolic BP Potassium | Diastolic BP Sodium | Diastolic BP Potassium |
|---------------|---------------|---------------|---------------|---------------|
| Unadjusted | -0.69 (0.17) | 0.78 (0.27) | -0.05 (0.11) | 0.88 (0.21) |
| Age and gender | 0.59 (0.16) | -1.09 (0.18) | 0.35 (0.10) | 0.26 (0.19) |
| Age, gender, BMI | 0.43 (0.16) | -0.96 (0.17) | 0.19 (0.10) | 0.38 (0.18) |

# Diagnostic

To assess model fit under a complex survey design, we visualize:

1.  Residuals vs Fitted with a survey-weighted smoother, and

2.  Partial residual curves (a la Figure 5.12 style) for key predictors.

Because `svyglm` drops rows with missing covariates, we must evaluate diagnostics on the same, non-missing subset. We therefore create `nonmissing` by removing `diag_model$na.action` from the original design, and then pass this design to `make.panel.svysmooth()` so that the smoother honors sampling weights, strata, and PSUs.

```{r}
# Choose which model to diagnose:
# - To mirror the textbook’s example, use m1 (age-adjusted)
# - To diagnose the fully adjusted model, use m3 (default here)
diag_model <- m3  # change to m1 if you want textbook’s exact choice

# Non-missing analytic subset used by diag_model
nonmissing <- des[-diag_model$na.action]
```

### 1) Residuals vs Fitted with survey-weighted smoother

```{r}
plot(diag_model,
     panel = make.panel.svysmooth(nonmissing))
```

Interpretation tips: Look for systematic curvature or funnel shapes. A flat smoother suggests no major mean-structure misspecification conditional on covariates.

### 2) Partial residual plots (weighted)

We draw partial residual curves using `termplot()` with `smooth = make.panel.svysmooth(nonmissing)`. This helps check linearity for continuous predictors such as `sodium`, `potassium`, and `RIDAGEYR` in the presence of adjustments.

```{r}
termplot(
  diag_model,
  data    = model.frame(nonmissing),
  partial = TRUE,
  se      = TRUE,
  smooth  = make.panel.svysmooth(nonmissing)
)
```

**Reading the plots:**

-   If the partial residual smoother for sodium or potassium shows notable curvature, a non-linear term (e.g., spline or transformation) may improve fit.

-   Wide shaded bands indicate higher uncertainty (often at intake extremes where survey weights up-weight fewer respondents).

# Interactions

We test whether the associations of sodium and potassium with blood pressure vary by age. Following the textbook, we center age at 40 so that:

-   the main effects for `sodium` and `potassium` represent effects at age 40;

-   the interaction coefficients represent the change in effect per 1-year increase in age.

## SBP model with interactions (Table 5.2)

```{r}
int_sbp <- svyglm(
  BPXSAR ~ (sodium + potassium) * I(RIDAGEYR - 40)
             + RIAGENDR + BMXBMI, design = des)
summary(int_sbp)
```

## DBP model with interactions (Table 5.2)

```{r}
int_dbp <- svyglm(
  BPXDAR ~ (sodium + potassium) * I(RIDAGEYR - 40)
             + RIAGENDR + BMXBMI, design = des)
summary(int_dbp)
```

## Marginal effects by age (readable summaries)

For interpretation, it’s useful to report the **age-specific slopes** of sodium and potassium (in g/day) at a few ages (e.g., 20, 40, 60). The slope for sodium at age *A* is:

$$
\beta_{\text{sodium}} + (A-40)\times \beta_{\text{sodium:age_c}}
$$

We compute these linear combinations (with standard errors and p-values) directly from the model coefficients and variance–covariance matrix.

```{r}
# Helper to compute age-specific slopes (linear combinations) for sodium/potassium
marginal_slopes <- function(mod, ages = c(20, 40, 60), terms = c("sodium","potassium")) {
  b  <- coef(mod)
  V  <- vcov(mod)
  df <- summary(mod)$df  # design-based df used by svyglm summaries

  build_row <- function(term, age) {
    agec <- age - 40
    main <- term
    inter <- paste0(term, ":age_c")
    if (!all(c(main, inter) %in% names(b))) stop("Term names not found in model: ", term)

    L <- rep(0, length(b)); names(L) <- names(b)
    L[main]  <- 1
    L[inter] <- agec

    est <- sum(L * b)
    se  <- sqrt(as.numeric(t(L) %*% V %*% L))
    tval <- est / se
    pval <- 2 * pt(abs(tval), df = df, lower.tail = FALSE)
    data.frame(term = term, age = age, slope = est, se = se, t = tval, p = pval)
  }

  do.call(rbind, lapply(terms, function(term)
    do.call(rbind, lapply(ages, function(a) build_row(term, a)))
  ))
}
```

**How to read these:**

-   For age = 40, the slope equals the model’s main effect (since `age_c = 0`).

-   For age = 60, the slope adjusts by `20 × (interaction coefficient)`; for age = 20, by `−20 × (interaction coefficient)`.

-   Report these as “mmHg change in SBP/DBP per 1 g/day increase” at the specified age.

**Reproduced Table 5.2 from desktop environment:**

|               | Systolic BP |           |          | Diastolic BP |           |          |
|-----------|-----------|-----------|-----------|-----------|-----------|-----------|
|               | Coefficient | Std Error | p-value  | Coefficient  | Std Error | p-value  |
| Sodium        | 0.310       | 0.166     | 0.075    | 0.310        | 0.114     | 0.012    |
| Potassium     | -0.976      | 0.183     | \< 0.001 | 0.326        | 0.182     | 0.087    |
| Sodium:Age    | -0.016      | 0.009     | 0.086    | 0.045        | 0.007     | \< 0.001 |
| Potassium:Age | -0.040      | 0.010     | \< 0.001 | -0.037       | 0.007     | \< 0.001 |

# Reproducibility Notes

We **did not** use `phonto::jointQuery()` or `phonto::unionQuery()` here, because we needed to (a) keep **all** BPX columns exactly as-is and (b) slice **DR1TOT** by **column positions** (C: `1:52,63,64`; D: `1:52,64,65`) to match the textbook byte-for-byte.

It seems like that we extracted a wide set of variables, yet the **models only need a small core**. This is due to the reasons of **fidelity & auditability, separation of concerns**:

-   to exactly match the textbook’s column selections by positions.

-   wide “retrieval” object for provenance; slim “analytic” object for modeling.

# Appendix

Graphs see `textbook_code_reproduce_replicate.qmd`.
